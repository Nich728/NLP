{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c7663db0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_file(filepath):\n",
    "    with open(filepath) as f:\n",
    "        str_text = f.read()\n",
    "        \n",
    "    return str_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "70014727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file('../UPDATED_NLP_COURSE/06-Deep-Learning/moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "660badbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_file('../UPDATED_NLP_COURSE/06-Deep-Learning/melville-moby_dick.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c590c445",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6560642",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_lg', disable=['parser', 'tagger', 'ner'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b30f056",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp.max_length = 1198623"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "63819afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def seperate_punc(doc_text):\n",
    "    return [token.text.lower() for token in nlp(doc_text) if token.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587a19ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = read_file('../UPDATED_NLP_COURSE/06-Deep-Learning/moby_dick_four_chapters.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abf14261",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = seperate_punc(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b224088d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11394"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8494b8de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 25 words --> network predict #26"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf8abc14",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_len = 25 + 1\n",
    "\n",
    "text_sequences = []\n",
    "\n",
    "for i in range(train_len, len(tokens)):\n",
    "    seq = tokens[i - train_len:i]\n",
    "    \n",
    "    text_sequences.append(seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c8927b7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ed3f23ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'call me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dbb6cfca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d46dcd2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ishmael some years ago never mind how long precisely having little or no money in my purse and nothing particular to interest me on shore i'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(text_sequences[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "696ce5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "feb973b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6253ff86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(text_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "458c65b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sequences[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "48722d0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "964 : call\n",
      "14 : me\n",
      "265 : ishmael\n",
      "51 : some\n",
      "263 : years\n",
      "416 : ago\n",
      "87 : never\n",
      "222 : mind\n",
      "129 : how\n",
      "111 : long\n",
      "962 : precisely\n",
      "262 : having\n",
      "50 : little\n",
      "43 : or\n",
      "37 : no\n",
      "321 : money\n",
      "7 : in\n",
      "23 : my\n",
      "555 : purse\n",
      "3 : and\n",
      "150 : nothing\n",
      "261 : particular\n",
      "6 : to\n",
      "2704 : interest\n",
      "14 : me\n",
      "24 : on\n"
     ]
    }
   ],
   "source": [
    "for i in sequences[0]:\n",
    "    print(f\"{i} : {tokenizer.index_word[i]}\")\n",
    "# tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "670ab956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenizer.word_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce17f4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_size = len(tokenizer.word_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dcc16e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2709"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocabulary_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3fb2e23a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "64baf55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "151a16e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = np.array(sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a5979782",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 964,   14,  265, ..., 2704,   14,   24],\n",
       "       [  14,  265,   51, ...,   14,   24,  965],\n",
       "       [ 265,   51,  263, ...,   24,  965,    5],\n",
       "       ...,\n",
       "       [ 960,   12,  168, ...,  264,   53,    2],\n",
       "       [  12,  168, 2703, ...,   53,    2, 2709],\n",
       "       [ 168, 2703,    3, ...,    2, 2709,   26]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "d1fcc06c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "37e69421",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = sequences[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ddeaeb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = sequences[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5fdc1f5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = to_categorical(y,num_classes=vocabulary_size+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d4a35fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_len = X.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ea9efa46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11368, 25)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "49ef62c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM, Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "44eb5d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(vocabulary_size, seq_len):\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(Embedding(vocabulary_size, seq_len, input_length=seq_len))\n",
    "    model.add(LSTM(seq_len * 2, return_sequences=True))\n",
    "    model.add(LSTM(seq_len * 2))\n",
    "    model.add(Dense(seq_len * 2, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    \n",
    "    model.summary()\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "9248863a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_2 (Embedding)      (None, 25, 25)            67750     \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 25, 50)            15200     \n",
      "_________________________________________________________________\n",
      "lstm_4 (LSTM)                (None, 50)                20200     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 50)                2550      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 2710)              138210    \n",
      "=================================================================\n",
      "Total params: 243,910\n",
      "Trainable params: 243,910\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_model(vocabulary_size+1, seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f91afce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pickle import dump,load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5a5dd10a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "11368/11368 [==============================] - 4s 359us/step - loss: 0.2021 - accuracy: 0.9624\n",
      "Epoch 2/50\n",
      "11368/11368 [==============================] - 4s 360us/step - loss: 0.1960 - accuracy: 0.9652\n",
      "Epoch 3/50\n",
      "11368/11368 [==============================] - 4s 362us/step - loss: 0.1903 - accuracy: 0.9661\n",
      "Epoch 4/50\n",
      "11368/11368 [==============================] - 4s 370us/step - loss: 0.1848 - accuracy: 0.9681\n",
      "Epoch 5/50\n",
      "11368/11368 [==============================] - 4s 366us/step - loss: 0.1835 - accuracy: 0.9682\n",
      "Epoch 6/50\n",
      "11368/11368 [==============================] - 4s 369us/step - loss: 0.1852 - accuracy: 0.9680\n",
      "Epoch 7/50\n",
      "11368/11368 [==============================] - 4s 369us/step - loss: 0.1902 - accuracy: 0.9656\n",
      "Epoch 8/50\n",
      "11368/11368 [==============================] - 4s 372us/step - loss: 0.1957 - accuracy: 0.9627\n",
      "Epoch 9/50\n",
      "11368/11368 [==============================] - 4s 373us/step - loss: 0.2051 - accuracy: 0.9599\n",
      "Epoch 10/50\n",
      "11368/11368 [==============================] - 4s 375us/step - loss: 0.2553 - accuracy: 0.9438\n",
      "Epoch 11/50\n",
      "11368/11368 [==============================] - 4s 376us/step - loss: 0.3564 - accuracy: 0.9094\n",
      "Epoch 12/50\n",
      "11368/11368 [==============================] - 4s 377us/step - loss: 0.5543 - accuracy: 0.8518\n",
      "Epoch 13/50\n",
      "11368/11368 [==============================] - 4s 374us/step - loss: 0.6230 - accuracy: 0.8281\n",
      "Epoch 14/50\n",
      "11368/11368 [==============================] - 4s 374us/step - loss: 0.5680 - accuracy: 0.8457\n",
      "Epoch 15/50\n",
      "11368/11368 [==============================] - 4s 376us/step - loss: 0.4595 - accuracy: 0.8749\n",
      "Epoch 16/50\n",
      "11368/11368 [==============================] - 4s 380us/step - loss: 0.3397 - accuracy: 0.9160\n",
      "Epoch 17/50\n",
      "11368/11368 [==============================] - 4s 378us/step - loss: 0.2581 - accuracy: 0.9412\n",
      "Epoch 18/50\n",
      "11368/11368 [==============================] - 4s 379us/step - loss: 0.2451 - accuracy: 0.9508\n",
      "Epoch 19/50\n",
      "11368/11368 [==============================] - 4s 379us/step - loss: 0.2256 - accuracy: 0.9546\n",
      "Epoch 20/50\n",
      "11368/11368 [==============================] - 4s 380us/step - loss: 0.2132 - accuracy: 0.9580\n",
      "Epoch 21/50\n",
      "11368/11368 [==============================] - 4s 381us/step - loss: 0.1980 - accuracy: 0.9634\n",
      "Epoch 22/50\n",
      "11368/11368 [==============================] - 4s 382us/step - loss: 0.1775 - accuracy: 0.9686\n",
      "Epoch 23/50\n",
      "11368/11368 [==============================] - 4s 384us/step - loss: 0.1652 - accuracy: 0.9716\n",
      "Epoch 24/50\n",
      "11368/11368 [==============================] - 4s 381us/step - loss: 0.1589 - accuracy: 0.9737\n",
      "Epoch 25/50\n",
      "11368/11368 [==============================] - 4s 381us/step - loss: 0.1591 - accuracy: 0.9741\n",
      "Epoch 26/50\n",
      "11368/11368 [==============================] - 4s 382us/step - loss: 0.1559 - accuracy: 0.9748\n",
      "Epoch 27/50\n",
      "11368/11368 [==============================] - 4s 385us/step - loss: 0.1531 - accuracy: 0.9748\n",
      "Epoch 28/50\n",
      "11368/11368 [==============================] - 4s 383us/step - loss: 0.1528 - accuracy: 0.9753\n",
      "Epoch 29/50\n",
      "11368/11368 [==============================] - 4s 384us/step - loss: 0.1495 - accuracy: 0.9751\n",
      "Epoch 30/50\n",
      "11368/11368 [==============================] - 4s 389us/step - loss: 0.1505 - accuracy: 0.9744\n",
      "Epoch 31/50\n",
      "11368/11368 [==============================] - 4s 392us/step - loss: 0.1576 - accuracy: 0.9735\n",
      "Epoch 32/50\n",
      "11368/11368 [==============================] - 4s 385us/step - loss: 0.1855 - accuracy: 0.9650\n",
      "Epoch 33/50\n",
      "11368/11368 [==============================] - 4s 387us/step - loss: 0.2811 - accuracy: 0.9324\n",
      "Epoch 34/50\n",
      "11368/11368 [==============================] - 4s 388us/step - loss: 0.6426 - accuracy: 0.8265\n",
      "Epoch 35/50\n",
      "11368/11368 [==============================] - 4s 385us/step - loss: 0.8324 - accuracy: 0.7755\n",
      "Epoch 36/50\n",
      "11368/11368 [==============================] - 4s 387us/step - loss: 0.6298 - accuracy: 0.8286\n",
      "Epoch 37/50\n",
      "11368/11368 [==============================] - 4s 389us/step - loss: 0.3884 - accuracy: 0.9001\n",
      "Epoch 38/50\n",
      "11368/11368 [==============================] - 4s 390us/step - loss: 0.2632 - accuracy: 0.9397\n",
      "Epoch 39/50\n",
      "11368/11368 [==============================] - 4s 387us/step - loss: 0.1932 - accuracy: 0.9654\n",
      "Epoch 40/50\n",
      "11368/11368 [==============================] - 4s 386us/step - loss: 0.1762 - accuracy: 0.9688\n",
      "Epoch 41/50\n",
      "11368/11368 [==============================] - 4s 386us/step - loss: 0.1615 - accuracy: 0.9714\n",
      "Epoch 42/50\n",
      "11368/11368 [==============================] - 4s 385us/step - loss: 0.1468 - accuracy: 0.9772\n",
      "Epoch 43/50\n",
      "11368/11368 [==============================] - 4s 389us/step - loss: 0.1402 - accuracy: 0.9780\n",
      "Epoch 44/50\n",
      "11368/11368 [==============================] - 4s 389us/step - loss: 0.1354 - accuracy: 0.9789\n",
      "Epoch 45/50\n",
      "11368/11368 [==============================] - 4s 386us/step - loss: 0.1333 - accuracy: 0.9797\n",
      "Epoch 46/50\n",
      "11368/11368 [==============================] - 4s 388us/step - loss: 0.1300 - accuracy: 0.9806\n",
      "Epoch 47/50\n",
      "11368/11368 [==============================] - 4s 389us/step - loss: 0.1303 - accuracy: 0.9800\n",
      "Epoch 48/50\n",
      "11368/11368 [==============================] - 4s 393us/step - loss: 0.1289 - accuracy: 0.9807\n",
      "Epoch 49/50\n",
      "11368/11368 [==============================] - 5s 404us/step - loss: 0.1297 - accuracy: 0.9807\n",
      "Epoch 50/50\n",
      "11368/11368 [==============================] - 4s 394us/step - loss: 0.1290 - accuracy: 0.9810\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x237eea3cb48>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size=128, epochs=50, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "c58e938d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('my_mobydick_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "52309342",
   "metadata": {},
   "outputs": [],
   "source": [
    "dump(tokenizer, open('my_simpletokenizer', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "54862d14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "0dbd2f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
    "    \n",
    "    output_text = []\n",
    "    \n",
    "    input_text = seed_text\n",
    "    \n",
    "    for i in range(num_gen_words):\n",
    "        \n",
    "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
    "        \n",
    "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
    "        \n",
    "        pred_word_ind = model.predict_classes(pad_encoded, verbose = 0)[0]\n",
    "        \n",
    "        pred_word = tokenizer.index_word[pred_word_ind]\n",
    "        \n",
    "        input_text += ' ' + pred_word\n",
    "        \n",
    "        output_text.append(pred_word)\n",
    "    \n",
    "    return ' '.join(output_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7e989935",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['call',\n",
       " 'me',\n",
       " 'ishmael',\n",
       " 'some',\n",
       " 'years',\n",
       " 'ago',\n",
       " 'never',\n",
       " 'mind',\n",
       " 'how',\n",
       " 'long',\n",
       " 'precisely',\n",
       " 'having',\n",
       " 'little',\n",
       " 'or',\n",
       " 'no',\n",
       " 'money',\n",
       " 'in',\n",
       " 'my',\n",
       " 'purse',\n",
       " 'and',\n",
       " 'nothing',\n",
       " 'particular',\n",
       " 'to',\n",
       " 'interest',\n",
       " 'me',\n",
       " 'on']"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sequences[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e18cd384",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "random.seed(42)\n",
    "random_pick = random.randint(0, len(text_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "0b2136d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_seed_text = text_sequences[random_pick]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "c64b84c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['predicament',\n",
       " 'for',\n",
       " 'though',\n",
       " 'i',\n",
       " 'tried',\n",
       " 'to',\n",
       " 'move',\n",
       " 'his',\n",
       " 'arm',\n",
       " 'unlock',\n",
       " 'his',\n",
       " 'bridegroom',\n",
       " 'clasp',\n",
       " 'yet',\n",
       " 'sleeping',\n",
       " 'as',\n",
       " 'he',\n",
       " 'was',\n",
       " 'he',\n",
       " 'still',\n",
       " 'hugged',\n",
       " 'me',\n",
       " 'tightly',\n",
       " 'as',\n",
       " 'though',\n",
       " 'naught']"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "e92ec4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_text = ' '.join(random_seed_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "42c0ad37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'predicament for though i tried to move his arm unlock his bridegroom clasp yet sleeping as he was he still hugged me tightly as though naught'"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seed_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "5f245e4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"was prepared again and my all the world oh yes devil captain ahab ' do were it not swerve me strove from thee orders ye\""
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generate_text(model, tokenizer, seq_len, seed_text=seed_text, num_gen_words=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28a9a69e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c5298855",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('../UPDATED_NLP_COURSE/06-Deep-Learning/epochBIG.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "b8035eb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = load(open('../UPDATED_NLP_COURSE/06-Deep-Learning/epochBIG', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf447a63",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
